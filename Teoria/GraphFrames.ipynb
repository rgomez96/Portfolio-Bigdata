{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de grafos en Spark con GraphFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que GraphFrames no es parte de Spark. Es un paquete externo que permite procesar grafos usando Spark DataFrames en lugar de los RDD menos cómodos, como hacía el antiguo módulo GraphX que sí es parte de Spark. Se espera que GraphFrames se incorpore oficialmente a Spark en el futuro cercano.\n",
    "\n",
    "Mientras tanto, primero debemos instalar el paquete GraphFrames para python, que es solo un wrapper de Python para el código Scala que contiene la implementación realmente paralela y distribuida. Podemos instalar el paquete de Python a través de `pip3 install`. Para la implementación de Scala, tenemos que indicar el paquete GraphFrames como \"Spark package\" que queremos usar en la opción de configuración `--packages` antes de crear el objeto SparkSession. Esto descargará la implementación GraphFrames para Scala sobre la marcha. El paquete de Python se basa por completo en dicho código Scala y generará un error si no se encuentra. Para que los notebooks de JupyterLab ya lleven esto incorporado, se añadió la propiedad de `spark.jars.packages` al crear el cluster en Dataproc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descargamos el fichero csv de vuelos y lo subimos a HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"wget\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n",
      "\"hdfs\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/olbapjose/xapi-clojure/master/flights_jan08.csv\n",
    "!hdfs dfs -copyFromLocal flights_jan08.csv /tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descargamos el paquete graphframes de python con el comando pip habitual de Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphframes\n",
      "  Downloading https://files.pythonhosted.org/packages/0b/27/c7c7e1ced2fe9a905f865dd91faaec2ac8a8e313f511678c8ec92a41a153/graphframes-0.6-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /opt/conda/anaconda/lib/python2.7/site-packages (from graphframes)\n",
      "Requirement already satisfied: nose in /opt/conda/anaconda/lib/python2.7/site-packages (from graphframes)\n",
      "Installing collected packages: graphframes\n",
      "Successfully installed graphframes-0.6\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install graphframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from graphframes import GraphFrame\n",
    "\n",
    "flightsDF = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/tmp/flights_jan08.csv\")\n",
    "verticesDF = flightsDF.select(F.col(\"Origin\").alias(\"id\")).distinct().cache()\n",
    "edgesDF = flightsDF.withColumnRenamed(\"Origin\", \"src\")\\\n",
    "                   .withColumnRenamed(\"Dest\", \"dst\")\\\n",
    "                   .select(\"src\", \"dst\", \"Distance\")\\\n",
    "                   .distinct()\\\n",
    "                   .cache() # select a few columns just to keep things simple\n",
    "                \n",
    "graph = GraphFrame(verticesDF, edgesDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a calcular los aeropuertos con más vuelos como aquellos con el grado más alto en su vértice (suma de ambos).\n",
    "Es sorprendente que el aeropuerto LAS (Las Vegas - McCarran International Airport) quede en primer lugar en número de vuelos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|degree|\n",
      "+---+------+\n",
      "|LAS|   108|\n",
      "|MDW|    94|\n",
      "|PHX|    84|\n",
      "+---+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph.degrees.orderBy(F.col(\"degree\").desc()).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|inDegree|\n",
      "+---+--------+\n",
      "|LAS|      54|\n",
      "|MDW|      47|\n",
      "|PHX|      42|\n",
      "+---+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph.inDegrees.orderBy(F.col(\"inDegree\").desc()).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| id|outDegree|\n",
      "+---+---------+\n",
      "|LAS|       54|\n",
      "|MDW|       47|\n",
      "|PHX|       42|\n",
      "+---+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph.outDegrees.orderBy(F.col(\"outDegree\").desc()).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PageRank para determinar la importancia global de los vértices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ejecutamos PageRank, que es un poco más sofisticado que contar simplemente el número de aristas que llegan o salen de cada vértice, confirma que LAS tiene importancia estratégica en nuestro grafo en base a las conexiones con otros aeropuertos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "| id|          pagerank|\n",
      "+---+------------------+\n",
      "|LAS|3.9681005880868927|\n",
      "|MDW| 3.464188596739582|\n",
      "|PHX|2.9996296419306288|\n",
      "|BWI| 2.859044345021574|\n",
      "|MCO| 2.506806330762528|\n",
      "|TPA| 2.325980728922274|\n",
      "|ABQ|  2.28062606472766|\n",
      "|HOU| 2.242821989285586|\n",
      "|BNA|2.1393487543945984|\n",
      "|SAN|  2.10337109753917|\n",
      "|MCI|1.9976511399324188|\n",
      "|AUS|1.8642893476111473|\n",
      "|STL|1.8263822546604833|\n",
      "|ONT|1.7722329347353263|\n",
      "|SAT|1.5303551318597992|\n",
      "|OAK|1.4886721798643956|\n",
      "|SMF|1.4779258223049847|\n",
      "|LAX|1.4134227909403223|\n",
      "|SLC| 1.362280151671023|\n",
      "|JAX|1.2637766842227056|\n",
      "+---+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ADVERTENCIA: pageRank tarda unos minutos en ejecutarse. Descomentar la siguiente línea si realmente queremos ejecutarlo :-)\n",
    "\n",
    "#ranks = graph.pageRank(resetProbability=0.15, maxIter=10)\n",
    "ranks.vertices.orderBy(F.col(\"pagerank\").desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Componentes conexas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nuestor grafo es posible llegar a cualquier aeropuerto desde cualquier otro, y por tanto solo hay una componente conexa y la columna `component` (identificador de la componente) tiene el mismo valor para todos los vértices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+\n",
      "| id|  component|\n",
      "+---+-----------+\n",
      "|MSY|17179869184|\n",
      "|GEG|17179869184|\n",
      "|BUR|17179869184|\n",
      "|SNA|17179869184|\n",
      "|PVD|17179869184|\n",
      "|OAK|17179869184|\n",
      "|ORF|17179869184|\n",
      "|CRW|17179869184|\n",
      "|CMH|17179869184|\n",
      "|IAH|17179869184|\n",
      "|SJC|17179869184|\n",
      "|BUF|17179869184|\n",
      "|AUS|17179869184|\n",
      "|LGB|17179869184|\n",
      "|BFL|17179869184|\n",
      "|RNO|17179869184|\n",
      "|CHS|17179869184|\n",
      "|HRL|17179869184|\n",
      "|RSW|17179869184|\n",
      "|TUL|17179869184|\n",
      "|AMA|17179869184|\n",
      "|ISP|17179869184|\n",
      "|MAF|17179869184|\n",
      "|EWR|17179869184|\n",
      "|LAS|17179869184|\n",
      "|JAN|17179869184|\n",
      "|DEN|17179869184|\n",
      "|ALB|17179869184|\n",
      "|BOI|17179869184|\n",
      "|IAD|17179869184|\n",
      "|SEA|17179869184|\n",
      "|MCI|17179869184|\n",
      "|BNA|17179869184|\n",
      "|CLT|17179869184|\n",
      "|ABQ|17179869184|\n",
      "|PBI|17179869184|\n",
      "|SDF|17179869184|\n",
      "|BDL|17179869184|\n",
      "|DAL|17179869184|\n",
      "|MRY|17179869184|\n",
      "|CLE|17179869184|\n",
      "|PDX|17179869184|\n",
      "|BWI|17179869184|\n",
      "|TPA|17179869184|\n",
      "|OKC|17179869184|\n",
      "|SMF|17179869184|\n",
      "|PHX|17179869184|\n",
      "|STL|17179869184|\n",
      "|MHT|17179869184|\n",
      "|LBB|17179869184|\n",
      "|CRP|17179869184|\n",
      "|SFO|17179869184|\n",
      "|ELP|17179869184|\n",
      "|BHM|17179869184|\n",
      "|FLL|17179869184|\n",
      "|DAY|17179869184|\n",
      "|OMA|17179869184|\n",
      "|LCH|17179869184|\n",
      "|LIT|17179869184|\n",
      "|FAT|17179869184|\n",
      "|ORD|17179869184|\n",
      "|RDU|17179869184|\n",
      "|MKE|17179869184|\n",
      "|SYR|17179869184|\n",
      "|LFT|17179869184|\n",
      "|PIT|17179869184|\n",
      "|TUS|17179869184|\n",
      "|MDW|17179869184|\n",
      "|COS|17179869184|\n",
      "|IND|17179869184|\n",
      "|DTW|17179869184|\n",
      "|HOU|17179869184|\n",
      "|ONT|17179869184|\n",
      "|JAX|17179869184|\n",
      "|LAX|17179869184|\n",
      "|BTR|17179869184|\n",
      "|MCO|17179869184|\n",
      "|ROC|17179869184|\n",
      "|SAN|17179869184|\n",
      "|PHL|17179869184|\n",
      "|SAT|17179869184|\n",
      "|SLC|17179869184|\n",
      "+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sparkContext.setCheckpointDir(\"/home/bigdata/data\")\n",
    "conCompResult = graph.connectedComponents(checkpointInterval=10)\n",
    "conCompResult.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consultas por estructura: rutas de vuelo entre aeropuertos sin conexión directa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos indicando que queremos encontrar vértices **a**, **b** y **c** para que haya una arista de **a** a **b**, otra de **b** a **c**, pero no de **a** a **c**, por lo tanto, **a** y **c** no están conectados en un solo salto sino que requieren al menos dos. La restricción adicional evita que **a** y **c** sean el mismo vértice, ya que ningún aeropuerto está conectado consigo mismo, por lo que cada aeropuerto cumpliría individualmente la condición respecto a sí mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+\n",
      "|    a|    b|    c|\n",
      "+-----+-----+-----+\n",
      "|[ABQ]|[LAX]|[BNA]|\n",
      "|[AMA]|[LAS]|[TUL]|\n",
      "|[AUS]|[MCI]|[PDX]|\n",
      "|[AUS]|[MDW]|[PVD]|\n",
      "|[AUS]|[PHX]|[STL]|\n",
      "|[BDL]|[MDW]|[DTW]|\n",
      "|[BHM]|[LAS]|[ELP]|\n",
      "|[BHM]|[MCO]|[ORF]|\n",
      "|[BNA]|[TPA]|[PBI]|\n",
      "|[BUF]|[LAS]|[MAF]|\n",
      "|[BUF]|[PHX]|[SNA]|\n",
      "|[BUR]|[PHX]|[OMA]|\n",
      "|[BUR]|[PHX]|[STL]|\n",
      "|[CLE]|[BWI]|[SAT]|\n",
      "|[CLE]|[MCO]|[ORF]|\n",
      "|[DAL]|[ABQ]|[MDW]|\n",
      "|[DAL]|[BHM]|[RDU]|\n",
      "|[DEN]|[PHX]|[SNA]|\n",
      "|[DTW]|[MDW]|[LIT]|\n",
      "|[DTW]|[STL]|[BHM]|\n",
      "+-----+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = graph\\\n",
    " .find(\"(a)-[]->(b); (b)-[]->(c); !(a)-[]->(c)\")\\\n",
    " .filter(\"c.id !=a.id\")\n",
    "\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caminos más cortos: Breadth-first search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a encontrar el camino más corto entre dos aeropuertos que no están directamente conectados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <b>IMPORTANTE</b>: BFS (Breadth-first search) en Spark calcula el camino mínimo en términos de <b>número de saltos</b> entre dos vértices. No tiene en cuenta el peso de las aristas. Se podría implementar pero de forma personalizada, no con la función bfs().\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hay varios caminos que tienen 2 saltos entre ABQ y BNA, la función `bfs` devuelve todos ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------+-----+----------------+-----+\n",
      "| from|              e0|   v1|              e1|   to|\n",
      "+-----+----------------+-----+----------------+-----+\n",
      "|[ABQ]| [ABQ, OAK, 889]|[OAK]|[OAK, BNA, 1959]|[BNA]|\n",
      "|[ABQ]| [ABQ, IAH, 744]|[IAH]| [IAH, BNA, 657]|[BNA]|\n",
      "|[ABQ]| [ABQ, AUS, 619]|[AUS]| [AUS, BNA, 756]|[BNA]|\n",
      "|[ABQ]| [ABQ, LAS, 487]|[LAS]|[LAS, BNA, 1588]|[BNA]|\n",
      "|[ABQ]| [ABQ, DEN, 349]|[DEN]|[DEN, BNA, 1013]|[BNA]|\n",
      "|[ABQ]|[ABQ, SEA, 1180]|[SEA]|[SEA, BNA, 1977]|[BNA]|\n",
      "|[ABQ]| [ABQ, MCI, 718]|[MCI]| [MCI, BNA, 491]|[BNA]|\n",
      "|[ABQ]|[ABQ, BWI, 1670]|[BWI]| [BWI, BNA, 588]|[BNA]|\n",
      "|[ABQ]|[ABQ, TPA, 1497]|[TPA]| [TPA, BNA, 612]|[BNA]|\n",
      "|[ABQ]| [ABQ, PHX, 328]|[PHX]|[PHX, BNA, 1448]|[BNA]|\n",
      "|[ABQ]|[ABQ, MDW, 1121]|[MDW]| [MDW, BNA, 395]|[BNA]|\n",
      "|[ABQ]| [ABQ, HOU, 759]|[HOU]| [HOU, BNA, 670]|[BNA]|\n",
      "|[ABQ]| [ABQ, ONT, 631]|[ONT]|[ONT, BNA, 1751]|[BNA]|\n",
      "|[ABQ]| [ABQ, LAX, 677]|[LAX]|[LAX, BNA, 1797]|[BNA]|\n",
      "|[ABQ]|[ABQ, MCO, 1552]|[MCO]| [MCO, BNA, 616]|[BNA]|\n",
      "|[ABQ]| [ABQ, SAN, 628]|[SAN]|[SAN, BNA, 1751]|[BNA]|\n",
      "|[ABQ]| [ABQ, SAT, 609]|[SAT]| [SAT, BNA, 822]|[BNA]|\n",
      "+-----+----------------+-----+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paths = graph.bfs(fromExpr = \"id = 'ABQ'\", toExpr= \"id = 'BNA'\")\n",
    "paths.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
