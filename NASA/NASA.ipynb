{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Server Logs Analysis\n",
    "\n",
    "De forma general, un server log es un archivo de log generado por un servidor con una lista de actividades que se ejecutan. En este caso tenemos un web server log el cuál mantiene un historial de las peticiones realizadas a la página. Este tipo de server logs tienen un formato standard Common Log Format (https://en.wikipedia.org/wiki/Common_Log_Format). Es una práctica general el analizar estos logs para sacar distintas conclusiones, localizar ataques, errores comunes, etc.\n",
    "\n",
    "En nuestro caso tenemos el dataset de los web server logs de la NASA, que están compuestos por este tipo de registros:\n",
    "\n",
    "133.43.96.45 - - [01/Aug/1995:00:00:23 -0400] \"GET /images/launch-logo.gif HTTP/1.0\" 200 1713\n",
    "\n",
    "Por lo que tenemos los siguientes campos:\n",
    "\n",
    "1. **Host:** 133.43.96.45\n",
    "2. **User-identifier:** En este dataset, todos los campos estarán con un \"-\" que significa que faltan esos datos, por lo que obviaremos este campo.\n",
    "3. **Userid:** También es obviado\n",
    "4. **Date:** 01/Aug/1995:00:00:23 -0400, como podemos ver está en formato dd/MMM/yyyy:HH:mm:ss y el campo final \"-0400\" sería el timezone que en este caso omitiremos, además haremos una transformación de los meses a forma numérica.\n",
    "5. **Request Method:** GET\n",
    "6. **Resource:** /images/launch-logo.gif, sería el recurso al que se accede en esta petición.\n",
    "7. **Protocol:** HTTP:/1.0, y por último en esta parte entre comillas tendríamos el protocolo utilizado al ser logs de 1995, seguramente sea el único protocolo utilizado.\n",
    "8. **HTTP status code:** 200, existen distintos códigos de estado de HTTP. Aquí tienes más información: https://en.wikipedia.org/wiki/List_of_HTTP_status_codes\n",
    "9. **Size:** 1713. El tamaño del objeto recibido por el cliente en bytes. En casos de error del cliente, este campo no se encuentra por lo que al igual que en los userid será indicado con un \"-\", tenerlo en cuenta.\n",
    "\n",
    "Ahora que ya entendemos que se encuentra dentro de nuestro web server log, vamos a pasar a analizarlo. Primero debemos cargar el archivo como un fichero de texto normal y realizar las transformaciones pertinentes. A la hora de limpiar y estructurar nuestro dataset utilizaremos expresiones regulares para recoger los campos que necesitamos.\n",
    "\n",
    "Ahora que ya entendemos qué se encuentra dentro de nuestro web sever log, vamos a pasar a analizarlo. Primero debemos cargar el archivo como un archivo de texto normal y realizar las transformaciones pertinentes, a la hora de limpiar y estructurar nuestro dataset utilizaremos expresiones regulares para recoger los campos que necesitamos.\n",
    "\n",
    "Guardaremos nuestro dataframe ya estructurado en formato parquet. Y este lo leeremos para realizar nuestro análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://L2111027.bosonit.local:4040\n",
       "SparkContext available as 'sc' (version = 3.1.2, master = local[*], app id = local-1643372301519)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@61aaafae\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession.builder()\n",
    "                        .appName(\"NASA\")\n",
    "                        .master(\"local\")\n",
    "                        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfAug: org.apache.spark.sql.DataFrame = [value: string]\r\n",
       "dfJul: org.apache.spark.sql.DataFrame = [value: string]\r\n",
       "df: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [value: string]\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Leo el dataset como texto\n",
    "val dfAug = spark.read.format(\"text\").load(\"access_log_Aug95\")\n",
    "val dfJul = spark.read.format(\"text\").load(\"access_log_Jul95\")\n",
    "\n",
    "val df= dfJul.union(dfAug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------+\n",
      "|value                                                                                                                  |\n",
      "+-----------------------------------------------------------------------------------------------------------------------+\n",
      "|199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245                                 |\n",
      "|unicomp6.unicomp.net - - [01/Jul/1995:00:00:06 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985                      |\n",
      "|199.120.110.21 - - [01/Jul/1995:00:00:09 -0400] \"GET /shuttle/missions/sts-73/mission-sts-73.html HTTP/1.0\" 200 4085   |\n",
      "|burger.letters.com - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 304 0               |\n",
      "|199.120.110.21 - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/missions/sts-73/sts-73-patch-small.gif HTTP/1.0\" 200 4179|\n",
      "+-----------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(numRows=5,truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------------+-------------+-----------------------------------------------+--------+--------------+----+\n",
      "|Host                |Date                      |RequestMethod|Resource                                       |Protocol|HTTPstatuscode|Size|\n",
      "+--------------------+--------------------------+-------------+-----------------------------------------------+--------+--------------+----+\n",
      "|199.72.81.55        |01/Jul/1995:00:00:01 -0400|GET          |/history/apollo/                               |HTTP/1.0|200           |6245|\n",
      "|unicomp6.unicomp.net|01/Jul/1995:00:00:06 -0400|GET          |/shuttle/countdown/                            |HTTP/1.0|200           |3985|\n",
      "|199.120.110.21      |01/Jul/1995:00:00:09 -0400|GET          |/shuttle/missions/sts-73/mission-sts-73.html   |HTTP/1.0|200           |4085|\n",
      "|burger.letters.com  |01/Jul/1995:00:00:11 -0400|GET          |/shuttle/countdown/liftoff.html                |HTTP/1.0|304           |0   |\n",
      "|199.120.110.21      |01/Jul/1995:00:00:11 -0400|GET          |/shuttle/missions/sts-73/sts-73-patch-small.gif|HTTP/1.0|200           |4179|\n",
      "|burger.letters.com  |01/Jul/1995:00:00:12 -0400|GET          |/images/NASA-logosmall.gif                     |HTTP/1.0|304           |0   |\n",
      "|burger.letters.com  |01/Jul/1995:00:00:12 -0400|GET          |/shuttle/countdown/video/livevideo.gif         |HTTP/1.0|200           |0   |\n",
      "|205.212.115.106     |01/Jul/1995:00:00:12 -0400|GET          |/shuttle/countdown/countdown.html              |HTTP/1.0|200           |3985|\n",
      "|d104.aa.net         |01/Jul/1995:00:00:13 -0400|GET          |/shuttle/countdown/                            |HTTP/1.0|200           |3985|\n",
      "|129.94.144.152      |01/Jul/1995:00:00:13 -0400|GET          |/                                              |HTTP/1.0|200           |7074|\n",
      "+--------------------+--------------------------+-------------+-----------------------------------------------+--------+--------------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "parsed_df: org.apache.spark.sql.DataFrame = [Host: string, Date: string ... 5 more fields]\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Utilizo un poco de brujería regex para asignar cada valor a cada columna.\n",
    "val parsed_df = df.select(regexp_extract($\"value\", exp=\"\"\"(.*) - - \\[(.*)\\] \"(\\S*) (\\S*) *(\\S*)\" ([\\d]*) (.*)\"\"\",groupIdx=1).alias(\"Host\"),\n",
    "regexp_extract($\"value\", exp=\"\"\"(.*) - - \\[(.*)\\] \"(\\S*) (\\S*) *(\\S*)\" ([\\d]*) (.*)\"\"\",groupIdx=2).alias(\"Date\"),\n",
    "regexp_extract($\"value\", exp=\"\"\"(.*) - - \\[(.*)\\] \"(\\S*) (\\S*) *(\\S*)\" ([\\d]*) (.*)\"\"\",groupIdx=3).alias(\"RequestMethod\"),\n",
    "regexp_extract($\"value\", exp=\"\"\"(.*) - - \\[(.*)\\] \"(\\S*) (\\S*) *(\\S*)\" ([\\d]*) (.*)\"\"\",groupIdx=4).alias(\"Resource\"),\n",
    "regexp_extract($\"value\", exp=\"\"\"(.*) - - \\[(.*)\\] \"(\\S*) (\\S*) *(\\S*)\" ([\\d]*) (.*)\"\"\",groupIdx=5).alias(\"Protocol\"),\n",
    "regexp_extract($\"value\", exp=\"\"\"(.*) - - \\[(.*)\\] \"(\\S*) (\\S*) *(\\S*)\" ([\\d]*) (.*)\"\"\",groupIdx=6).alias(\"HTTPstatuscode\"),\n",
    "regexp_extract($\"value\", exp=\"\"\"(.*) - - \\[(.*)\\] \"(\\S*) (\\S*) *(\\S*)\" ([\\d]*) (.*)\"\"\",groupIdx=7).alias(\"Size\")).na.drop()\n",
    "\n",
    "parsed_df.show(numRows=10, truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------------+-------------+-----------------------------------------------+--------+--------------+----+\n",
      "|Host                |Date                      |RequestMethod|Resource                                       |Protocol|HTTPstatuscode|Size|\n",
      "+--------------------+--------------------------+-------------+-----------------------------------------------+--------+--------------+----+\n",
      "|199.72.81.55        |01/Jul/1995:00:00:01 -0400|GET          |/history/apollo/                               |HTTP/1.0|200           |6245|\n",
      "|unicomp6.unicomp.net|01/Jul/1995:00:00:06 -0400|GET          |/shuttle/countdown/                            |HTTP/1.0|200           |3985|\n",
      "|199.120.110.21      |01/Jul/1995:00:00:09 -0400|GET          |/shuttle/missions/sts-73/mission-sts-73.html   |HTTP/1.0|200           |4085|\n",
      "|burger.letters.com  |01/Jul/1995:00:00:11 -0400|GET          |/shuttle/countdown/liftoff.html                |HTTP/1.0|304           |0   |\n",
      "|199.120.110.21      |01/Jul/1995:00:00:11 -0400|GET          |/shuttle/missions/sts-73/sts-73-patch-small.gif|HTTP/1.0|200           |4179|\n",
      "|burger.letters.com  |01/Jul/1995:00:00:12 -0400|GET          |/images/NASA-logosmall.gif                     |HTTP/1.0|304           |0   |\n",
      "|burger.letters.com  |01/Jul/1995:00:00:12 -0400|GET          |/shuttle/countdown/video/livevideo.gif         |HTTP/1.0|200           |0   |\n",
      "|205.212.115.106     |01/Jul/1995:00:00:12 -0400|GET          |/shuttle/countdown/countdown.html              |HTTP/1.0|200           |3985|\n",
      "|d104.aa.net         |01/Jul/1995:00:00:13 -0400|GET          |/shuttle/countdown/                            |HTTP/1.0|200           |3985|\n",
      "|129.94.144.152      |01/Jul/1995:00:00:13 -0400|GET          |/                                              |HTTP/1.0|200           |7074|\n",
      "+--------------------+--------------------------+-------------+-----------------------------------------------+--------+--------------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "parsed_df: org.apache.spark.sql.DataFrame = [Host: string, Date: string ... 5 more fields]\r\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Utilizo un poco de brujería regex para asignar cada valor a cada columna.\n",
    "val parsed_df = df.select(regexp_extract($\"value\", exp=\"\"\"(.*) - - \\[(.*)\\] \"(\\S*) (\\S*) *(\\S*)\" (.*) (.*)\"\"\",groupIdx=1).alias(\"Host\"),\n",
    "regexp_extract($\"value\", exp=\"\"\"(.*) - - \\[(.*)\\] \"(\\S*) (\\S*) *(\\S*)\" (.*) (.*)\"\"\",groupIdx=2).alias(\"Date\"),\n",
    "regexp_extract($\"value\", exp=\"\"\"(.*) - - \\[(.*)\\] \"(\\S*) (\\S*) *(\\S*)\" (.*) (.*)\"\"\",groupIdx=3).alias(\"RequestMethod\"),\n",
    "regexp_extract($\"value\", exp=\"\"\"(.*) - - \\[(.*)\\] \"(\\S*) (\\S*) *(\\S*)\" (.*) (.*)\"\"\",groupIdx=4).alias(\"Resource\"),\n",
    "regexp_extract($\"value\", exp=\"\"\"(.*) - - \\[(.*)\\] \"(\\S*) (\\S*) *(\\S*)\" (.*) (.*)\"\"\",groupIdx=5).alias(\"Protocol\"),\n",
    "regexp_extract($\"value\", exp=\"\"\"(.*) - - \\[(.*)\\] \"(\\S*) (\\S*) *(\\S*)\" (.*) (.*)\"\"\",groupIdx=6).alias(\"HTTPstatuscode\"),\n",
    "regexp_extract($\"value\", exp=\"\"\"(.*) - - \\[(.*)\\] \"(\\S*) (\\S*) *(\\S*)\" (.*) (.*)\"\"\",groupIdx=7).alias(\"Size\")).na.drop()\n",
    "\n",
    "parsed_df.show(numRows=10, truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+-------------+--------------------+--------+--------------+----+\n",
      "|            Host|                Date|RequestMethod|            Resource|Protocol|HTTPstatuscode|Size|\n",
      "+----------------+--------------------+-------------+--------------------+--------+--------------+----+\n",
      "|dsl.rhilinet.gov|16/Aug/1995:11:17...|          GET|/software/winvn/w...|       a|           404|   -|\n",
      "+----------------+--------------------+-------------+--------------------+--------+--------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//parsed_df.where(($\"Protocol\"!==\"STS-69</a><p>\") && ($\"Protocol\" !== \"a\")).where($\"host\"===\"\").show()\n",
    "parsed_df.where($\"Protocol\"===\"a\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parsed_limpio: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Host: string, Date: string ... 5 more fields]\r\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val parsed_limpio=parsed_df.where(($\"Host\" !== \"\") && ($\"Date\" !== \"\") && ($\"RequestMethod\" !== \"\") && ($\"Resource\" !== \"\") &&\n",
    "                                  ($\"Protocol\" !== \"\") && ($\"HTTPstatuscode\" !== \"\") && ($\"Size\" !==\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Guardo el dataset estructurado en formato Parquet.\n",
    "//parsed_limpio.write.parquet(\"C:/Users/rafael.gomez/Documents/EjerciciosSpark/NASA/dfparsed\")\n",
    "parsed_df129.188.154.200 - - [01/Jul/1995:00:03:58 -0400] \"GET / HTTP/1.0\" 200 7074.write.format(\"parquet\")\n",
    "                .mode(\"overwrite\")\n",
    "                .save(\"C:/Users/rafael.gomez/Documents/EjerciciosSpark/NASA/dfparsed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------------+-------------+-----------------------------------------------+--------+--------------+----+\n",
      "|Host                |Date                      |RequestMethod|Resource                                       |Protocol|HTTPstatuscode|Size|\n",
      "+--------------------+--------------------------+-------------+-----------------------------------------------+--------+--------------+----+\n",
      "|199.72.81.55        |01/Jul/1995:00:00:01 -0400|GET          |/history/apollo/                               |HTTP/1.0|200           |6245|\n",
      "|unicomp6.unicomp.net|01/Jul/1995:00:00:06 -0400|GET          |/shuttle/countdown/                            |HTTP/1.0|200           |3985|\n",
      "|199.120.110.21      |01/Jul/1995:00:00:09 -0400|GET          |/shuttle/missions/sts-73/mission-sts-73.html   |HTTP/1.0|200           |4085|\n",
      "|burger.letters.com  |01/Jul/1995:00:00:11 -0400|GET          |/shuttle/countdown/liftoff.html                |HTTP/1.0|304           |0   |\n",
      "|199.120.110.21      |01/Jul/1995:00:00:11 -0400|GET          |/shuttle/missions/sts-73/sts-73-patch-small.gif|HTTP/1.0|200           |4179|\n",
      "+--------------------+--------------------------+-------------+-----------------------------------------------+--------+--------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "parqDF: org.apache.spark.sql.DataFrame = [Host: string, Date: string ... 5 more fields]\r\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Vuelvo a leerlo porque... lo pide el enunciado.\n",
    "val parqDF = spark.read.parquet(\"C:/Users/rafael.gomez/Documents/EjerciciosSpark/NASA/dfparsed\")\n",
    "\n",
    "parqDF.show(5,false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuáles son los distintos protocolos web utilizados? Agrúpalos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|     Protocol|\n",
      "+-------------+\n",
      "|       HTTP/*|\n",
      "|            a|\n",
      "|    HTTP/V1.0|\n",
      "|     HTTP/1.0|\n",
      "|STS-69</a><p>|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parqDF.select($\"Protocol\").distinct().show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuáles son los códigos de estado más comunes en la web? Agrúpalos y ordénalos para ver cuál es el más común."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+\n",
      "|HTTPstatuscode|count(1)|\n",
      "+--------------+--------+\n",
      "|           200| 3094323|\n",
      "|           304|  266764|\n",
      "|           302|   72966|\n",
      "|           404|   20628|\n",
      "|           403|     225|\n",
      "|           500|      65|\n",
      "|           501|      41|\n",
      "+--------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parqDF.groupBy($\"HTTPstatuscode\").agg(count(\"*\")).orderBy(desc(\"count(1)\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ¿Y los métodos de petición (verbos) más utilizados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n",
      "|RequestMethod|count(1)|\n",
      "+-------------+--------+\n",
      "|          GET| 3446875|\n",
      "|         HEAD|    7915|\n",
      "|         POST|     222|\n",
      "+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parqDF.groupBy($\"RequestMethod\").agg(count(\"*\")).orderBy(desc(\"count(1)\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué recurso tuvo la mayor transferencia de bytes de la página web?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+-------+\n",
      "|resource                               |size   |\n",
      "+---------------------------------------+-------+\n",
      "|/shuttle/countdown/video/livevideo.jpeg|6823936|\n",
      "+---------------------------------------+-------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions._\r\n",
       "import org.apache.spark.sql.types.IntegerType\r\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types.IntegerType\n",
    "\n",
    "parqDF.withColumn(\"size\", col(\"size\").cast(IntegerType)).orderBy(desc(\"size\")).select(col(\"resource\"),col(\"size\")).show(1,false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Además, queremos saber que recurso de nuestra web es el que más tráfico recibe. Es decir, el recurso con más registros en nuestro log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+------+\n",
      "|resource                  |count |\n",
      "+--------------------------+------+\n",
      "|/images/NASA-logosmall.gif|208353|\n",
      "+--------------------------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parqDF.withColumn(\"Size\",col(\"Size\").cast(IntegerType)).groupBy(col(\"resource\")).agg(count(\"resource\").alias(\"count\")).orderBy(desc(\"count\")).show(1,false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué días la web recibió más tráfico?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|date       |count(date)|\n",
      "+-----------+-----------+\n",
      "|13/Jul/1995|133883     |\n",
      "|06/Jul/1995|100833     |\n",
      "|05/Jul/1995|94445      |\n",
      "|12/Jul/1995|92094      |\n",
      "|31/Aug/1995|89739      |\n",
      "+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dateDF: org.apache.spark.sql.DataFrame = [Host: string, date: string ... 5 more fields]\r\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dateDF=parqDF.withColumn(\"date\",substring_index(col(\"date\"),\":\",1))\n",
    "dateDF.groupBy(col(\"date\")).agg(count(\"date\")).orderBy(desc(\"count(date)\")).show(5,false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuáles son los hosts son los más frecuentes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|Host                |count(Host)|\n",
      "+--------------------+-----------+\n",
      "|piweba3y.prodigy.com|21988      |\n",
      "|piweba4y.prodigy.com|16437      |\n",
      "|piweba1y.prodigy.com|12825      |\n",
      "|edams.ksc.nasa.gov  |11962      |\n",
      "|163.206.89.4        |9697       |\n",
      "+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parqDF.groupBy(col(\"Host\")).agg(count(\"Host\")).orderBy(desc(\"count(Host)\")).show(5,false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿A qué horas se produce el mayor número de tráfico en la web?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+\n",
      "|hora|count(hora)|\n",
      "+----+-----------+\n",
      "|15  |230298     |\n",
      "|12  |226928     |\n",
      "|13  |225082     |\n",
      "|14  |223396     |\n",
      "|16  |217143     |\n",
      "+----+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "horaDF: org.apache.spark.sql.DataFrame = [Host: string, Date: string ... 6 more fields]\r\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val horaDF=parqDF.withColumn(\"hora\",substring(col(\"date\"),13,2))\n",
    "horaDF.groupBy(col(\"hora\")).agg(count(\"hora\")).orderBy(desc(\"count(hora)\")).show(5,false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuál es el número de errores 404 que ha habido cada día?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Host: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- RequestMethod: string (nullable = true)\n",
      " |-- Resource: string (nullable = true)\n",
      " |-- Protocol: string (nullable = true)\n",
      " |-- HTTPstatuscode: string (nullable = true)\n",
      " |-- Size: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dateDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+\n",
      "|       date|404s|\n",
      "+-----------+----+\n",
      "|19/Jul/1995| 636|\n",
      "|06/Jul/1995| 630|\n",
      "|30/Aug/1995| 564|\n",
      "|07/Jul/1995| 563|\n",
      "|31/Aug/1995| 525|\n",
      "|13/Jul/1995| 524|\n",
      "|07/Aug/1995| 523|\n",
      "|05/Jul/1995| 492|\n",
      "|03/Jul/1995| 473|\n",
      "|11/Jul/1995| 469|\n",
      "|18/Jul/1995| 463|\n",
      "|12/Jul/1995| 459|\n",
      "|25/Jul/1995| 458|\n",
      "|20/Jul/1995| 427|\n",
      "|24/Aug/1995| 419|\n",
      "|25/Aug/1995| 411|\n",
      "|29/Aug/1995| 411|\n",
      "|14/Jul/1995| 407|\n",
      "|28/Aug/1995| 405|\n",
      "|17/Jul/1995| 403|\n",
      "+-----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dateDF.where(col(\"HTTPstatuscode\")===\"404\").groupBy(\"date\").agg(count(\"*\").alias(\"404s\")).orderBy(desc(\"404s\")).show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
